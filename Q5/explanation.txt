Increasing the learning rate from 0.2 to 0.4 decreased the accuracy of the boosted decision tree model. I suspect that it was not able to converge to as accurate an answer due to the higher change between learning iterations. I wanted to see if perhaps there would be  a more accurate answer if the model was allowed to change more, but I suppose the main advantage of cloud computing is that you can afford to use a lower learning rate and still do all the computation necessary to get a better answer.